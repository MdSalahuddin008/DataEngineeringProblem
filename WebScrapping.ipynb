{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9acdd2ec-abe5-4dbc-b0ef-14e5e9065705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "Found 10 listings\n",
      "Scraping page 2...\n",
      "Found 10 listings\n",
      "Scraping page 3...\n",
      "Found 10 listings\n",
      "Scraping page 4...\n",
      "Found 10 listings\n",
      "Scraping page 5...\n",
      "Found 10 listings\n",
      "Scraping page 6...\n",
      "Found 10 listings\n",
      "Scraping page 7...\n",
      "Found 10 listings\n",
      "Scraping page 8...\n",
      "Found 10 listings\n",
      "✅ Saved 80 records to indiamart_industrial_pumps_selenium.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "BASE_URL = \"https://dir.indiamart.com/search.mp?ss=industrial+pumps&prdsrc=1\"\n",
    "NUM_PAGES = 8\n",
    "OUTPUT_FILE = \"indiamart_industrial_pumps_selenium.csv\"\n",
    "\n",
    "# -------------- SELENIUM SETUP --------------\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# ---------------- SCRAPER ----------------\n",
    "all_data = []\n",
    "\n",
    "for page in range(1, NUM_PAGES + 1):\n",
    "    url = f\"{BASE_URL}&page={page}\"\n",
    "    print(f\"Scraping page {page}...\")\n",
    "    driver.get(url)\n",
    "    time.sleep(3)  # wait for dynamic content\n",
    "\n",
    "    cards = driver.find_elements(By.CLASS_NAME, \"card\")\n",
    "    print(f\"Found {len(cards)} listings\")\n",
    "\n",
    "    for card in cards:\n",
    "        # Product name + URL\n",
    "        try:\n",
    "            product_tag = card.find_element(By.TAG_NAME, \"a\")\n",
    "            product_name = product_tag.text.strip()\n",
    "            product_url = product_tag.get_attribute(\"href\")\n",
    "        except:\n",
    "            product_name = None\n",
    "            product_url = None\n",
    "\n",
    "        # Supplier name\n",
    "        try:\n",
    "            supplier_name = card.find_element(By.CLASS_NAME, \"companyname\").text.strip()\n",
    "        except:\n",
    "            supplier_name = None\n",
    "\n",
    "        # Location (fetch from innerText of card)\n",
    "        try:\n",
    "            full_text = card.text  # all text inside the card\n",
    "    # check for common city/state keywords\n",
    "            possible_locations = [\"Delhi\", \"Karnataka\", \"Maharashtra\", \"Telangana\", \"Gujarat\", \"Tamil Nadu\",\n",
    "                          \"Andhra Pradesh\", \"West Bengal\", \"Kerala\", \"Bengaluru\", \"Mumbai\", \"Hyderabad\"]\n",
    "            location = None\n",
    "            for loc in possible_locations:\n",
    "                if loc in full_text:\n",
    "            # extract the full line containing the location\n",
    "                    lines = full_text.split(\"\\n\")\n",
    "                    for line in lines:\n",
    "                        if loc in line:\n",
    "                            location = line.strip()\n",
    "                            break\n",
    "                if location:\n",
    "                    break\n",
    "        except:\n",
    "            location = None\n",
    "\n",
    "\n",
    "        # Price\n",
    "        try:\n",
    "            price_text = card.find_element(By.CLASS_NAME, \"price\").text\n",
    "            price_text = price_text.replace(\"₹\", \"\").replace(\",\", \"\").strip()\n",
    "            try:\n",
    "                price = int(price_text)\n",
    "            except:\n",
    "                price = None\n",
    "        except:\n",
    "            price = None\n",
    "\n",
    "        all_data.append({\n",
    "            \"product_name\": product_name,\n",
    "            \"supplier_name\": supplier_name,\n",
    "            \"category\": \"Industrial Pumps\",\n",
    "            \"location\": location,\n",
    "            \"price\": price,\n",
    "            \"product_url\": product_url\n",
    "        })\n",
    "\n",
    "    time.sleep(2)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# ---------------- SAVE CSV ----------------\n",
    "df = pd.DataFrame(all_data)\n",
    "df.to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "print(f\"✅ Saved {len(df)} records to {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede7d566-7988-4192-87a8-0b5b9570a9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
